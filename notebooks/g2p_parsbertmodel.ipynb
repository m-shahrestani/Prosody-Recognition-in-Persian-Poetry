{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "WA_C0axGlhQz"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount(\"/content/drive/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "e1JMhm5xlhcL"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VERSE1</th>\n",
       "      <th>VERSE2</th>\n",
       "      <th>PROSODY</th>\n",
       "      <th>PROSODY_ID</th>\n",
       "      <th>VERSE1_phoneme</th>\n",
       "      <th>VERSE2_phoneme</th>\n",
       "      <th>PROSODY_phoneme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>‏ آتش آهم ز بس گلزار بی نم می شود</td>\n",
       "      <td>برگ گل سنگ ته دندان شبنم می شود</td>\n",
       "      <td>فاعلاتن فاعلاتن فاعلاتن فاعلن</td>\n",
       "      <td>12</td>\n",
       "      <td>‏ ātaš āham ze bas golzār bi nam mišavad</td>\n",
       "      <td>barg gol sang tah dandān šabnam mišavad</td>\n",
       "      <td>fā`elānt fā`elānt fā`elānt fā`elan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>‏ بهیچوجه نیارم برید ازو که مرا</td>\n",
       "      <td>به دل محبت او چون صفاست با گوهر</td>\n",
       "      <td>مفاعلن فعلاتن مفاعلن فعلن</td>\n",
       "      <td>92</td>\n",
       "      <td>‏ bahyxube nayāram barid ozav ke marā</td>\n",
       "      <td>be del mohbat u čon sefāsat bā gohar</td>\n",
       "      <td>mafā`elen fal`ānt mafā`elen fe`lan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>‏ بی تکلف ز شکر ریزی صائب جویا</td>\n",
       "      <td>طوطی نطق تو طرز سخن آموخته است</td>\n",
       "      <td>فعلاتن فعلاتن فعلاتن فعلن</td>\n",
       "      <td>45</td>\n",
       "      <td>‏ bi taklef ze šekar rizi sā`eb juyā</td>\n",
       "      <td>tuti notq to tarz soxan āmustened</td>\n",
       "      <td>fal`ānt fal`ānt fal`ānt fe`lan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>‏ چنان کز شهد و شکر نقل نوشین می‌شود پیدا</td>\n",
       "      <td>چو لب بر لب گذاری جان شیرین می‌شود پیدا</td>\n",
       "      <td>مفاعیلن مفاعیلن مفاعیلن مفاعیلن</td>\n",
       "      <td>114</td>\n",
       "      <td>‏ čenān kez šahd va šekar naql nušin mišavad p...</td>\n",
       "      <td>čo lab bar lab gozāri jān širin mišavad peydā</td>\n",
       "      <td>mafā`eliyān mafā`eliyān mafā`eliyān mafā`eliyān</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>‏ خواهم که خدا روی به دولت بگشاید</td>\n",
       "      <td>زین درگه امید عرب را و عجم را</td>\n",
       "      <td>مفعول مفاعیل مفاعیل فعولن</td>\n",
       "      <td>163</td>\n",
       "      <td>‏ xāhomeko xodā ravi be dolat begošāyad</td>\n",
       "      <td>yzn dargah omid arab rā va ajam rā</td>\n",
       "      <td>maf`ul mafā`e`il mafā`e`il fe`olan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339684</th>\n",
       "      <td>ییشش بخوانده ‌غاصب کالیسی‌‌</td>\n",
       "      <td>مستد برانه آیت ولّو را‌</td>\n",
       "      <td>مفعول فاعلات مفاعیلن</td>\n",
       "      <td>143</td>\n",
       "      <td>yeš`ege bexānde qa`asb kālisi</td>\n",
       "      <td>mostad berāne āyat velv rā`</td>\n",
       "      <td>maf`ul fā`elāt mafā`eliyān</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339685</th>\n",
       "      <td>ییش‌هر تختی یکی خوان ظریف</td>\n",
       "      <td>وندر آن گسترده دیبایی لطیف</td>\n",
       "      <td>فاعلاتن فاعلاتن فاعلن</td>\n",
       "      <td>16</td>\n",
       "      <td>ye^lang taxti ye^ki xān zarif</td>\n",
       "      <td>venedr ān gostarde dibā`i latif</td>\n",
       "      <td>fā`elānt fā`elānt fā`elan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339686</th>\n",
       "      <td>ییشوایان بهر فردا گرم شور</td>\n",
       "      <td>هریکی گوبا به دیگرگونه طور</td>\n",
       "      <td>فاعلاتن فاعلاتن فاعلن</td>\n",
       "      <td>16</td>\n",
       "      <td>yejviyān ba^hre fardā garm šur</td>\n",
       "      <td>haryeki govā be digargune tor</td>\n",
       "      <td>fā`elānt fā`elānt fā`elan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339687</th>\n",
       "      <td>ییک باره‌ای برنشسته سمند</td>\n",
       "      <td>بفتراک بربسته دارد کمند</td>\n",
       "      <td>فعولن فعولن فعولن فعل</td>\n",
       "      <td>54</td>\n",
       "      <td>yezak hāre`e barnešaste samand</td>\n",
       "      <td>beftārt barbaste dārad kamand</td>\n",
       "      <td>fe`olan fe`olan fe`olan fe`l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339688</th>\n",
       "      <td>یین حق بود کین گفت از نهانی</td>\n",
       "      <td>نشان خود ز عین بی نشانی</td>\n",
       "      <td>مفاعیلن مفاعیلن فعولن</td>\n",
       "      <td>109</td>\n",
       "      <td>yanj haq bud kin goft az nahāni</td>\n",
       "      <td>nešān xud ze eyn bi nešāni</td>\n",
       "      <td>mafā`eliyān mafā`eliyān fe`olan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1339689 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            VERSE1  \\\n",
       "0                ‏ آتش آهم ز بس گلزار بی نم می شود   \n",
       "1                  ‏ بهیچوجه نیارم برید ازو که مرا   \n",
       "2                   ‏ بی تکلف ز شکر ریزی صائب جویا   \n",
       "3        ‏ چنان کز شهد و شکر نقل نوشین می‌شود پیدا   \n",
       "4                ‏ خواهم که خدا روی به دولت بگشاید   \n",
       "...                                            ...   \n",
       "1339684                ییشش بخوانده ‌غاصب کالیسی‌‌   \n",
       "1339685                  ییش‌هر تختی یکی خوان ظریف   \n",
       "1339686                  ییشوایان بهر فردا گرم شور   \n",
       "1339687                   ییک باره‌ای برنشسته سمند   \n",
       "1339688                یین حق بود کین گفت از نهانی   \n",
       "\n",
       "                                          VERSE2  \\\n",
       "0                برگ گل سنگ ته دندان شبنم می شود   \n",
       "1                به دل محبت او چون صفاست با گوهر   \n",
       "2                 طوطی نطق تو طرز سخن آموخته است   \n",
       "3        چو لب بر لب گذاری جان شیرین می‌شود پیدا   \n",
       "4                  زین درگه امید عرب را و عجم را   \n",
       "...                                          ...   \n",
       "1339684                  مستد برانه آیت ولّو را‌   \n",
       "1339685               وندر آن گسترده دیبایی لطیف   \n",
       "1339686               هریکی گوبا به دیگرگونه طور   \n",
       "1339687                  بفتراک بربسته دارد کمند   \n",
       "1339688                  نشان خود ز عین بی نشانی   \n",
       "\n",
       "                                  PROSODY  PROSODY_ID  \\\n",
       "0          فاعلاتن فاعلاتن فاعلاتن فاعلن           12   \n",
       "1              مفاعلن فعلاتن مفاعلن فعلن           92   \n",
       "2              فعلاتن فعلاتن فعلاتن فعلن           45   \n",
       "3        مفاعیلن مفاعیلن مفاعیلن مفاعیلن          114   \n",
       "4              مفعول مفاعیل مفاعیل فعولن          163   \n",
       "...                                   ...         ...   \n",
       "1339684             مفعول فاعلات مفاعیلن          143   \n",
       "1339685            فاعلاتن فاعلاتن فاعلن           16   \n",
       "1339686            فاعلاتن فاعلاتن فاعلن           16   \n",
       "1339687            فعولن فعولن فعولن فعل           54   \n",
       "1339688            مفاعیلن مفاعیلن فعولن          109   \n",
       "\n",
       "                                            VERSE1_phoneme  \\\n",
       "0                 ‏ ātaš āham ze bas golzār bi nam mišavad   \n",
       "1                    ‏ bahyxube nayāram barid ozav ke marā   \n",
       "2                     ‏ bi taklef ze šekar rizi sā`eb juyā   \n",
       "3        ‏ čenān kez šahd va šekar naql nušin mišavad p...   \n",
       "4                  ‏ xāhomeko xodā ravi be dolat begošāyad   \n",
       "...                                                    ...   \n",
       "1339684                      yeš`ege bexānde qa`asb kālisi   \n",
       "1339685                      ye^lang taxti ye^ki xān zarif   \n",
       "1339686                     yejviyān ba^hre fardā garm šur   \n",
       "1339687                     yezak hāre`e barnešaste samand   \n",
       "1339688                    yanj haq bud kin goft az nahāni   \n",
       "\n",
       "                                        VERSE2_phoneme  \\\n",
       "0              barg gol sang tah dandān šabnam mišavad   \n",
       "1                 be del mohbat u čon sefāsat bā gohar   \n",
       "2                    tuti notq to tarz soxan āmustened   \n",
       "3        čo lab bar lab gozāri jān širin mišavad peydā   \n",
       "4                   yzn dargah omid arab rā va ajam rā   \n",
       "...                                                ...   \n",
       "1339684                    mostad berāne āyat velv rā`   \n",
       "1339685                venedr ān gostarde dibā`i latif   \n",
       "1339686                  haryeki govā be digargune tor   \n",
       "1339687                  beftārt barbaste dārad kamand   \n",
       "1339688                     nešān xud ze eyn bi nešāni   \n",
       "\n",
       "                                         PROSODY_phoneme  \n",
       "0                     fā`elānt fā`elānt fā`elānt fā`elan  \n",
       "1                     mafā`elen fal`ānt mafā`elen fe`lan  \n",
       "2                         fal`ānt fal`ānt fal`ānt fe`lan  \n",
       "3        mafā`eliyān mafā`eliyān mafā`eliyān mafā`eliyān  \n",
       "4                     maf`ul mafā`e`il mafā`e`il fe`olan  \n",
       "...                                                  ...  \n",
       "1339684                       maf`ul fā`elāt mafā`eliyān  \n",
       "1339685                        fā`elānt fā`elānt fā`elan  \n",
       "1339686                        fā`elānt fā`elānt fā`elan  \n",
       "1339687                     fe`olan fe`olan fe`olan fe`l  \n",
       "1339688                  mafā`eliyān mafā`eliyān fe`olan  \n",
       "\n",
       "[1339689 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "wp = pd.read_csv('../weighted_phonemes.csv')\n",
    "wp.drop('Unnamed: 0', inplace=True, axis=1)\n",
    "wp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r3x3Sxz8uHzW"
   },
   "source": [
    "# **Balance Sample**  \n",
    "2000 records  from each 55 popular prosodies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "C1Uf06AC5tIs"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Turbo\\AppData\\Local\\Temp\\ipykernel_4484\\36628110.py:8: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  bsmp = result.groupby('PROSODY_ID').apply(select_random_rows).reset_index(drop=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_counts = wp.groupby('PROSODY_ID').size()\n",
    "filtered_ids = id_counts[id_counts >= 100]\n",
    "result = wp[wp['PROSODY_ID'].isin(filtered_ids.index)]\n",
    "\n",
    "def select_random_rows(group):\n",
    "    n = min(500, len(group))\n",
    "    return group.sample(n=n)\n",
    "bsmp = result.groupby('PROSODY_ID').apply(select_random_rows).reset_index(drop=True)\n",
    "numberclass = len(set(bsmp[\"PROSODY_ID\"]))\n",
    "numberclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DTswDk2quZqk"
   },
   "source": [
    "shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "aJ89ZHLGDQPg"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VERSE1</th>\n",
       "      <th>VERSE2</th>\n",
       "      <th>PROSODY</th>\n",
       "      <th>PROSODY_ID</th>\n",
       "      <th>VERSE1_phoneme</th>\n",
       "      <th>VERSE2_phoneme</th>\n",
       "      <th>PROSODY_phoneme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>سروی ز بستان ارم، شمع شبستان حرم</td>\n",
       "      <td>رویش گلستان عجم کویش دلستان دیده‌ام</td>\n",
       "      <td>مستفعلن مستفعلن مستفعلن مستفعلن</td>\n",
       "      <td>83</td>\n",
       "      <td>soruy ze besetān aram ، šam` šabestān haram</td>\n",
       "      <td>ruyeš golestān ajam keyoš dolsāne dideam</td>\n",
       "      <td>mosta`felan mosta`felan mosta`felan mosta`felan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>پس فضل فاضلان نه به اعراض است</td>\n",
       "      <td>ای مرد، نه مگر به قد و بالا</td>\n",
       "      <td>مفعول فاعلات مفاعیلن</td>\n",
       "      <td>143</td>\n",
       "      <td>pas fazl fāzelān noh be e`rāz ast</td>\n",
       "      <td>ey mard ، noh magar be qad va bālā</td>\n",
       "      <td>maf`ul fā`elāt mafā`eliyān</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>اندر شبان تاریک جیحون دو چیز خواهد</td>\n",
       "      <td>هم روی ماهتابی هم ماهتاب روئی</td>\n",
       "      <td>مفعول فاعلاتن مفعول فاعلاتن</td>\n",
       "      <td>147</td>\n",
       "      <td>andar šobān tārik jeyhun do čiz</td>\n",
       "      <td>ham ravi māhtābi ham māhtāb ru`i</td>\n",
       "      <td>maf`ul fā`elānt maf`ul fā`elānt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>در سماع عشق، محفل گرم بود</td>\n",
       "      <td>چون سپند از جای جستم یللی</td>\n",
       "      <td>مستفعلتن مستفعلتن</td>\n",
       "      <td>70</td>\n",
       "      <td>dar samā` ešq ، mahfel garm bud</td>\n",
       "      <td>čon sepand az jāy jostam ylyli</td>\n",
       "      <td>mostaf`altan mostaf`altan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>سالارشان را نیکو بودکار</td>\n",
       "      <td>احرار را نیز دل باد بیدار</td>\n",
       "      <td>مستفعلن فع مستفعلن فع</td>\n",
       "      <td>72</td>\n",
       "      <td>sālāršān rā niku budkār</td>\n",
       "      <td>ahrār rā niz del bād bidār</td>\n",
       "      <td>mosta`felan fa` mosta`felan fa`</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21467</th>\n",
       "      <td>ره پر شکن است پر بیفکن</td>\n",
       "      <td>تیغ است قوی سپر بیفکن</td>\n",
       "      <td>مفعول مفاعلن فعولن</td>\n",
       "      <td>154</td>\n",
       "      <td>rah por šekan ast por biyāfkan</td>\n",
       "      <td>tiq ast qavi separ biyāfkan</td>\n",
       "      <td>maf`ul mafā`elen fe`olan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21468</th>\n",
       "      <td>کنون از شکوفه‌ام شک افتاده در ضمیر</td>\n",
       "      <td>که گر شیرخواره‌است به صورت چراست پیر</td>\n",
       "      <td>فعولن مفاعلن فعولن مفاعلن</td>\n",
       "      <td>59</td>\n",
       "      <td>konun az šokufate šak oftāde dar zamir</td>\n",
       "      <td>kahger širxārestād be surat čarāsat pir</td>\n",
       "      <td>fe`olan mafā`elen fe`olan mafā`elen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21469</th>\n",
       "      <td>گوئی که رسی به مرگ از هجرم</td>\n",
       "      <td>هجر تو ز مرگ وا نمیمٰاند</td>\n",
       "      <td>مفعول مفاعلن مفاعیلن</td>\n",
       "      <td>156</td>\n",
       "      <td>go`i ke rasi be marg az hejrm</td>\n",
       "      <td>hejr to ze marg vā nemimānad</td>\n",
       "      <td>maf`ul mafā`elen mafā`eliyān</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21470</th>\n",
       "      <td>چو پیچد به نسرین او شاخ سنبل</td>\n",
       "      <td>ز مرآت، مرئی شود نقش جوهر</td>\n",
       "      <td>فعولن فعولن فعولن فعولن</td>\n",
       "      <td>55</td>\n",
       "      <td>čo pičad be nasrin u šāx sonbol</td>\n",
       "      <td>ze mar`āt ، marā`i šavad naqš johar</td>\n",
       "      <td>fe`olan fe`olan fe`olan fe`olan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21471</th>\n",
       "      <td>بدین خدمت مرا از عالم پیر</td>\n",
       "      <td>امید دولت از بخت جوان است</td>\n",
       "      <td>مفعول مفاعلن مفاعیلن</td>\n",
       "      <td>156</td>\n",
       "      <td>bedin xedmat marā az ālam pir</td>\n",
       "      <td>omid dolat az baxt javān ast</td>\n",
       "      <td>maf`ul mafā`elen mafā`eliyān</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21472 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   VERSE1  \\\n",
       "0        سروی ز بستان ارم، شمع شبستان حرم   \n",
       "1           پس فضل فاضلان نه به اعراض است   \n",
       "2      اندر شبان تاریک جیحون دو چیز خواهد   \n",
       "3               در سماع عشق، محفل گرم بود   \n",
       "4                 سالارشان را نیکو بودکار   \n",
       "...                                   ...   \n",
       "21467              ره پر شکن است پر بیفکن   \n",
       "21468  کنون از شکوفه‌ام شک افتاده در ضمیر   \n",
       "21469          گوئی که رسی به مرگ از هجرم   \n",
       "21470        چو پیچد به نسرین او شاخ سنبل   \n",
       "21471           بدین خدمت مرا از عالم پیر   \n",
       "\n",
       "                                     VERSE2                           PROSODY  \\\n",
       "0       رویش گلستان عجم کویش دلستان دیده‌ام  مستفعلن مستفعلن مستفعلن مستفعلن    \n",
       "1               ای مرد، نه مگر به قد و بالا             مفعول فاعلات مفاعیلن    \n",
       "2             هم روی ماهتابی هم ماهتاب روئی      مفعول فاعلاتن مفعول فاعلاتن    \n",
       "3                 چون سپند از جای جستم یللی                 مستفعلتن مستفعلتن   \n",
       "4                 احرار را نیز دل باد بیدار            مستفعلن فع مستفعلن فع    \n",
       "...                                     ...                               ...   \n",
       "21467                 تیغ است قوی سپر بیفکن               مفعول مفاعلن فعولن    \n",
       "21468  که گر شیرخواره‌است به صورت چراست پیر         فعولن مفاعلن فعولن مفاعلن   \n",
       "21469              هجر تو ز مرگ وا نمیمٰاند             مفعول مفاعلن مفاعیلن    \n",
       "21470             ز مرآت، مرئی شود نقش جوهر          فعولن فعولن فعولن فعولن    \n",
       "21471             امید دولت از بخت جوان است             مفعول مفاعلن مفاعیلن    \n",
       "\n",
       "       PROSODY_ID                               VERSE1_phoneme  \\\n",
       "0              83  soruy ze besetān aram ، šam` šabestān haram   \n",
       "1             143            pas fazl fāzelān noh be e`rāz ast   \n",
       "2             147              andar šobān tārik jeyhun do čiz   \n",
       "3              70              dar samā` ešq ، mahfel garm bud   \n",
       "4              72                      sālāršān rā niku budkār   \n",
       "...           ...                                          ...   \n",
       "21467         154               rah por šekan ast por biyāfkan   \n",
       "21468          59       konun az šokufate šak oftāde dar zamir   \n",
       "21469         156                go`i ke rasi be marg az hejrm   \n",
       "21470          55              čo pičad be nasrin u šāx sonbol   \n",
       "21471         156                bedin xedmat marā az ālam pir   \n",
       "\n",
       "                                 VERSE2_phoneme  \\\n",
       "0      ruyeš golestān ajam keyoš dolsāne dideam   \n",
       "1            ey mard ، noh magar be qad va bālā   \n",
       "2              ham ravi māhtābi ham māhtāb ru`i   \n",
       "3                čon sepand az jāy jostam ylyli   \n",
       "4                    ahrār rā niz del bād bidār   \n",
       "...                                         ...   \n",
       "21467               tiq ast qavi separ biyāfkan   \n",
       "21468   kahger širxārestād be surat čarāsat pir   \n",
       "21469              hejr to ze marg vā nemimānad   \n",
       "21470       ze mar`āt ، marā`i šavad naqš johar   \n",
       "21471              omid dolat az baxt javān ast   \n",
       "\n",
       "                                       PROSODY_phoneme  \n",
       "0      mosta`felan mosta`felan mosta`felan mosta`felan  \n",
       "1                           maf`ul fā`elāt mafā`eliyān  \n",
       "2                      maf`ul fā`elānt maf`ul fā`elānt  \n",
       "3                            mostaf`altan mostaf`altan  \n",
       "4                      mosta`felan fa` mosta`felan fa`  \n",
       "...                                                ...  \n",
       "21467                         maf`ul mafā`elen fe`olan  \n",
       "21468              fe`olan mafā`elen fe`olan mafā`elen  \n",
       "21469                     maf`ul mafā`elen mafā`eliyān  \n",
       "21470                  fe`olan fe`olan fe`olan fe`olan  \n",
       "21471                     maf`ul mafā`elen mafā`eliyān  \n",
       "\n",
       "[21472 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import shuffle\n",
    "\n",
    "row_indices = bsmp.index.tolist()\n",
    "shuffle(row_indices)\n",
    "bsmp = bsmp.iloc[row_indices]\n",
    "bsmp = bsmp.reset_index(drop=True)\n",
    "bsmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "wiY8_YexL8yK"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "21472"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "id_counts = bsmp['PROSODY_ID'].value_counts()\n",
    "id_counts_sorted = id_counts.sort_index()\n",
    "\n",
    "plt.bar(id_counts_sorted.index, id_counts_sorted)\n",
    "plt.show()\n",
    "records = len(bsmp)\n",
    "records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vTXKXcatbQTZ"
   },
   "source": [
    "#Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "nCyukmNkbO8C"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\turbo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.38.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\turbo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\turbo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\turbo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\turbo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\turbo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\turbo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in c:\\users\\turbo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\turbo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\turbo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\turbo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\turbo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\turbo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.8.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\turbo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\turbo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\turbo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\turbo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\turbo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Jc-ET4hFbO6D"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchtext import vocab as Vocab\n",
    "import collections\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "class processed_dataset(Dataset):\n",
    "    def __init__(self, data, vocab):\n",
    "        self.tokenized_data = [[vocab.stoi[word.lower()] for word in self.tokenize_sent(data_tuple[0])] for data_tuple in data]\n",
    "        self.labels = [data_tuple[1] for data_tuple in data]\n",
    "        assert len(self.labels) == len(self.tokenized_data)\n",
    "\n",
    "    def tokenize_sent(self, sent):\n",
    "        return [word for word in sent.split(' ')]\n",
    "\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.tokenized_data[idx], self.labels[idx]\n",
    "\n",
    "\n",
    "class processed_dataset_bert(Dataset):\n",
    "    def __init__(self, data, bert_type):\n",
    "        tokenizer = AutoTokenizer.from_pretrained(bert_type)\n",
    "        self.texts = []\n",
    "        self.labels = []\n",
    "        for text, label in data:\n",
    "            self.texts.append(torch.tensor(tokenizer.encode(text, max_length=128, truncation=True)))\n",
    "            self.labels.append(label)\n",
    "        assert len(self.texts) == len(self.labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx], self.labels[idx]\n",
    "\n",
    "\n",
    "class packDataset_util():\n",
    "    def __init__(self, vocab_target_set):\n",
    "        self.vocab = self.get_vocab(vocab_target_set)\n",
    "\n",
    "    def fn(self, data):\n",
    "        labels = torch.tensor([item[1] for item in data])\n",
    "        lengths = [len(item[0]) for item in data]\n",
    "        texts = [torch.tensor(item[0]) for item in data]\n",
    "        padded_texts = pad_sequence(texts, batch_first=True, padding_value=0)\n",
    "\n",
    "        return padded_texts, lengths, labels\n",
    "\n",
    "    def get_loader(self, data, shuffle=True, batch_size=32):\n",
    "        dataset = processed_dataset(data, self.vocab)\n",
    "        loader = DataLoader(dataset=dataset, shuffle=shuffle, batch_size=batch_size, collate_fn=self.fn)\n",
    "        return loader\n",
    "\n",
    "    def tokenize_sent(self, sent):\n",
    "        return [word for word in sent.split(' ')]\n",
    "\n",
    "\n",
    "    def get_vocab(self, target_set):\n",
    "        tokenized_data = [[word.lower() for word in self.tokenize_sent(data_tuple[0])] for data_tuple in target_set]\n",
    "        counter = collections.Counter([word for review in tokenized_data for word in review])\n",
    "        vocab = Vocab.Vocab(counter, min_freq=3)\n",
    "        return vocab\n",
    "\n",
    "\n",
    "class packDataset_util_bert():\n",
    "    def __init__(self, bert_type):\n",
    "        self.bert_type = bert_type\n",
    "\n",
    "    def fn(self, data):\n",
    "        texts = []\n",
    "        labels = []\n",
    "        for text, label in data:\n",
    "            texts.append(text)\n",
    "            labels.append(label)\n",
    "        labels = torch.tensor(labels)\n",
    "        padded_texts = pad_sequence(texts, batch_first=True, padding_value=0)\n",
    "        attention_masks = torch.zeros_like(padded_texts).masked_fill(padded_texts != 0, 1)\n",
    "        return padded_texts, attention_masks, labels\n",
    "\n",
    "\n",
    "    def get_loader(self, data, shuffle=True, batch_size=32):\n",
    "        dataset = processed_dataset_bert(data, self.bert_type)\n",
    "        loader = DataLoader(dataset=dataset, shuffle=shuffle, batch_size=batch_size, collate_fn=self.fn)\n",
    "        return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "GO8pWQJ3bO4N"
   },
   "outputs": [],
   "source": [
    "packDataset_util = packDataset_util_bert(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "cFNC-cQWMOKz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34354"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "train=[]\n",
    "for i in range(0, math.floor(records * 0.8)):\n",
    "  train.append((bsmp[\"VERSE1_phoneme\"][i], bsmp[\"PROSODY_ID\"][i]))\n",
    "  train.append((bsmp[\"VERSE2_phoneme\"][i], bsmp[\"PROSODY_ID\"][i]))\n",
    "len(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "4c79306b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8590"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=[]\n",
    "for i in range(math.floor(records * 0.8), records):\n",
    "  test.append((bsmp[\"VERSE1_phoneme\"][i],bsmp[\"PROSODY_ID\"][i]))\n",
    "  test.append((bsmp[\"VERSE2_phoneme\"][i],bsmp[\"PROSODY_ID\"][i]))\n",
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "jxqQYt9NbO2N"
   },
   "outputs": [],
   "source": [
    "train_loader = packDataset_util.get_loader(train, shuffle=False, batch_size=128)\n",
    "test_loader = packDataset_util.get_loader(test, shuffle=False, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "VpVtOoe2bOyb"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "import os\n",
    "from torch.nn.utils import clip_grad_norm_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "2mx6e4FnbqZD"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "hCLqfcpZbqWv"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at HooshvareLab/bert-base-parsbert-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"HooshvareLab/bert-base-parsbert-uncased\"\n",
    "                                                     , num_labels=176).to(device) # because we have 11 classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IwRs7yKjEp55"
   },
   "source": [
    "#Optional\n",
    "if you load a trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "JRJzdKp9EuL_"
   },
   "outputs": [],
   "source": [
    "# Only if you want to resume your previous epochs\n",
    "# model.load_state_dict(torch.load(\"your_checkpoint.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Nkz9lkk9bqUk"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "SYonxMkMbqSr"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "weight_decay = float(0)\n",
    "lr = 1e-5\n",
    "EPOCHS = 10\n",
    "warm_up_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "2vc7FVmCbqQv"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "yG10vNiMbqOs"
   },
   "outputs": [],
   "source": [
    "scheduler = transformers.get_linear_schedule_with_warmup(optimizer,\n",
    "                                        num_warmup_steps=warm_up_epochs * len(train_loader),\n",
    "                                        num_training_steps=(warm_up_epochs + EPOCHS) * len(train_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "aip_VRXJbqMi"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "import warnings\n",
    "def evaluaion(loader):\n",
    "    warnings.filterwarnings('ignore')\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for padded_text, attention_masks, labels in loader:\n",
    "            padded_text = padded_text.to(device)\n",
    "            attention_masks = attention_masks.to(device)\n",
    "            labels = labels.to(device)\n",
    "            output = model(padded_text, attention_masks)[0]  # batch_size, 2\n",
    "            _, flag = torch.max(output, dim=1)\n",
    "\n",
    "            # add true and predicted labels for calculating F1 score\n",
    "            y_true += labels.cpu().numpy().tolist()\n",
    "            y_pred += flag.cpu().numpy().tolist()\n",
    "\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "        precision = precision_score(y_true, y_pred, average='weighted')\n",
    "        recall = recall_score(y_true, y_pred, average='weighted')\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        return acc, f1, precision, recall, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "GHhPPgiQgo_z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is 3A20-2AB6\n",
      "\n",
      " Directory of C:\\Users\\Turbo\\Desktop\\persian_poem_prosody_research\\RES\\g2p_parsbert\n",
      "\n",
      "03/18/2024  04:20 PM    <DIR>          .\n",
      "03/18/2024  04:20 PM    <DIR>          ..\n",
      "03/15/2024  07:06 PM    <DIR>          .ipynb_checkpoints\n",
      "03/17/2024  04:25 PM           368,025 g2p_parsbert-1336930.html\n",
      "03/17/2024  04:10 PM       651,991,049 g2p_parsbert-1336930.pth\n",
      "03/18/2024  03:58 PM           364,450 g2p_parsbert-138520.html\n",
      "03/18/2024  03:56 PM       651,990,844 g2p_parsbert-138520.pth\n",
      "03/18/2024  02:57 PM           364,705 g2p_parsbert-243686.html\n",
      "03/18/2024  02:41 PM       651,990,844 g2p_parsbert-243686.pth\n",
      "03/18/2024  04:16 PM           363,312 g2p_parsbert-38293.html\n",
      "03/18/2024  04:15 PM       651,990,639 g2p_parsbert-38293.pth\n",
      "03/16/2024  02:26 AM           360,940 g2p_parsbert-5500.html\n",
      "03/16/2024  02:26 AM       651,990,434 g2p_parsbert-5500.pth\n",
      "03/18/2024  01:09 PM           365,381 g2p_parsbert-726511.html\n",
      "03/18/2024  10:24 AM       651,990,844 g2p_parsbert-726511.pth\n",
      "03/18/2024  04:20 PM            53,217 g2p_parsbertmodel.ipynb\n",
      "              13 File(s)  3,914,184,684 bytes\n",
      "               3 Dir(s)  339,439,820,800 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "jo1hoFwueRmC",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish training, avg loss: 4.955842838854594/100000, begin to evaluate:\n",
      "test accuracy: 0.026542491268917345, Epoch time = 36.32189359999029\n",
      "*****************************************************************************************\n",
      "finish training, avg loss: 4.303193256314359/4.955842838854594, begin to evaluate:\n",
      "test accuracy: 0.04458672875436554, Epoch time = 35.23728100000881\n",
      "*****************************************************************************************\n",
      "finish training, avg loss: 3.7402093206639626/4.303193256314359, begin to evaluate:\n",
      "test accuracy: 0.06670547147846333, Epoch time = 35.66925400000764\n",
      "*****************************************************************************************\n",
      "finish training, avg loss: 3.4308645095967005/3.7402093206639626, begin to evaluate:\n",
      "test accuracy: 0.08649592549476134, Epoch time = 35.94617660000222\n",
      "*****************************************************************************************\n",
      "finish training, avg loss: 3.2742706417594256/3.4308645095967005, begin to evaluate:\n",
      "test accuracy: 0.09790454016298021, Epoch time = 35.94352549998439\n",
      "*****************************************************************************************\n",
      "finish training, avg loss: 3.176068146432643/3.2742706417594256, begin to evaluate:\n",
      "test accuracy: 0.09860302677532014, Epoch time = 36.03543749998789\n",
      "*****************************************************************************************\n",
      "finish training, avg loss: 3.107702163072324/3.176068146432643, begin to evaluate:\n",
      "test accuracy: 0.1089639115250291, Epoch time = 36.05618910002522\n",
      "*****************************************************************************************\n",
      "finish training, avg loss: 3.0534529393490364/3.107702163072324, begin to evaluate:\n",
      "test accuracy: 0.1149010477299185, Epoch time = 36.09165889999713\n",
      "*****************************************************************************************\n",
      "finish training, avg loss: 3.0064782192272768/3.0534529393490364, begin to evaluate:\n",
      "test accuracy: 0.11641443538998836, Epoch time = 36.10818169999402\n",
      "*****************************************************************************************\n",
      "finish training, avg loss: 2.965486134738284/3.0064782192272768, begin to evaluate:\n",
      "test accuracy: 0.11979045401629802, Epoch time = 36.14158729999326\n",
      "*****************************************************************************************\n",
      "finish training, avg loss: 2.9264069782313804/2.965486134738284, begin to evaluate:\n",
      "test accuracy: 0.12724097788125727, Epoch time = 36.14583260001382\n",
      "*****************************************************************************************\n",
      "finish training, avg loss: 2.8998088003534366/2.9264069782313804, begin to evaluate:\n",
      "test accuracy: 0.12968568102444702, Epoch time = 36.165838999993866\n",
      "*****************************************************************************************\n",
      "finish training, avg loss: 2.879589922809246/2.8998088003534366, begin to evaluate:\n",
      "test accuracy: 0.13655413271245634, Epoch time = 36.270784299995285\n",
      "*****************************************************************************************\n",
      "*****************************************************************************************\n",
      "train time = 468.13364109999384\n",
      "finish all, final test accuracy: 0.13655413271245634, F1 score: 0.1116475727631848, Precision: 0.11824943956282369, Recall: 0.13655413271245634, Confusion Matrix: [[ 0  0  0 ...  0  0  0]\n",
      " [ 0 20  0 ...  1  3  1]\n",
      " [ 0  0 44 ...  0  2  9]\n",
      " ...\n",
      " [ 0  6  0 ...  6  1  0]\n",
      " [ 0  6  1 ...  6 11 12]\n",
      " [ 0  2  1 ...  0 15 28]]\n",
      "finish all, final train accuracy: 0.1793095418291902, F1 score: 0.14848466519749343, Precision: 0.19134673319908913, Recall: 0.1793095418291902, Confusion Matrix: [[  0   0   0 ...   0   0   0]\n",
      " [  0  98   0 ...  20   6   1]\n",
      " [  0   0 217 ...   0   2  11]\n",
      " ...\n",
      " [  0  41   0 ...  30   3   1]\n",
      " [  0  21   0 ...   4  67  18]\n",
      " [  0   9   3 ...   0  82 127]]\n"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "last_train_avg_loss = 100000\n",
    "epoch_times = []\n",
    "for epoch in range(warm_up_epochs + EPOCHS): # you can change number of epochs\n",
    "    start_time = timer()\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for padded_text, attention_masks, labels in train_loader:\n",
    "        padded_text = padded_text.to(device)\n",
    "        attention_masks = attention_masks.to(device)\n",
    "        labels = labels.to(device)\n",
    "        output = model(padded_text, attention_masks)[0]\n",
    "        loss = criterion(output, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        total_loss += loss.item()\n",
    "    end_time = timer()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f'finish training, avg loss: {avg_loss}/{last_train_avg_loss}, begin to evaluate:')\n",
    "    test_acc, _, _, _, _ = evaluaion(test_loader)\n",
    "    et = end_time - start_time\n",
    "    epoch_times.append(et)\n",
    "    print(f'test accuracy: {test_acc}, Epoch time = {et}')\n",
    "    last_train_avg_loss = avg_loss\n",
    "    print('*' * 89)\n",
    "\n",
    "torch.save(model.state_dict(), f\"g2p_parsbert-{records}.pth\")\n",
    "acc, f1, precision, recall, cm = evaluaion(test_loader)\n",
    "train_acc, train_f1, train_precision, train_recall, train_cm = evaluaion(train_loader)\n",
    "print('*' * 89)\n",
    "print(f'train time = {sum(epoch_times)}')\n",
    "print(f'finish all, final test accuracy: {acc}, F1 score: {f1}, Precision: {precision}, Recall: {recall}, Confusion Matrix: {cm}')\n",
    "print(f'finish all, final train accuracy: {train_acc}, F1 score: {train_f1}, Precision: {train_precision}, Recall: {train_recall}, Confusion Matrix: {train_cm}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOY5EqFvt002SmQhE5jQZni",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
